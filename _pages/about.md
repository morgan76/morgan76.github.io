---
layout: about
title: About
permalink: /

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
---

Hello! I'm a postdoctoral researcher at CNRS in Nantes, working with [Dr. Vincent Lostanlen](https://lostanlen.com/) on **Multi-Resolution Neural Networks for audio (MuReNN)**. I completed my PhD at the [ADASP Group](https://adasp.telecom-paris.fr/) at Télécom Paris, where I was jointly supervised by [Prof. Slim Essid](https://slimessid.github.io/research/) and [Brian McFee](https://brianmcfee.net/) from New York University.

My research lies at the intersection of machine learning, signal processing, and audio data analysis, with a particular focus on Music Information Retrieval (MIR).

### Academic Journey

- **2014–2019**: I earned a master’s degree in Applied Mathematics from the Institut National des Sciences Appliquées de Rouen, France.  
- **2018–2019**: I was a graduate exchange student at École Polytechnique de Montréal, Canada.  
- **2020–2021**: I completed the master’s program in Sound & Music Computing at the [Music Technology Group (MTG)](https://www.upf.edu/web/mtg/) at Pompeu Fabra University in Barcelona, Spain.  
- **2021–2024**: I was a doctoral researcher at the Audio Data Analysis and Signal Processing Group at Télécom Paris (Institut Polytechnique de Paris). My doctoral research focused on Music Structure Analysis. You can access my thesis manuscript [here](https://theses.hal.science/tel-04980794/).  
- **Summer 2024**: I completed a research internship at Spotify, supervised by [Dr. Rachel Bittner](https://rachelbittner.github.io/), where I worked on **music summarization**.  

### Research Focus

Estimating song structures is a crucial task in Music Information Retrieval, yet it presents challenges due to the ambiguity of structure annotations and the scarcity of labeled data. My PhD research addressed these issues through three main approaches:

1. **Self-supervised Learning for Music Segmentation** — I developed methods that leverage prior musical knowledge, such as the hierarchical nature of music structure, to learn audio representations that enhance segmentation performance without labeled data.

2. **Graph-based Music Structure Analysis** — By framing music structure analysis as a link prediction task, I applied deep graph learning techniques to achieve state-of-the-art segmentation results with minimal supervision, improving both performance and interpretability.

3. **Multimodal Learning with Language Models** — I explored the connection between text and audio, utilizing language models to tackle ambiguities in music structure annotations.

### What's Next?

I am currently a postdoctoral researcher at CNRS, exploring how multi-resolution neural networks can advance the analysis and modeling of audio signals in the waveform domain.

If you're interested in my work or potential collaborations, feel free to reach out!
